{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "notebookName": "SparkDataframe-CSV-solution",
      "dashboards": [],
      "notebookMetadata": {
        "pythonIndentUnit": 2
      },
      "language": "python",
      "widgets": {},
      "notebookOrigID": 620345572627578
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veroorli/ProjetProg/blob/master/TME622.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "710d6dff-49b3-4ff2-8082-441223d45842"
        },
        "id": "OyxZGhX_gpjy"
      },
      "source": [
        "* Master DAC, BDLE, 2022\n",
        "* Author: Mohamed-Amine Baazizi\n",
        "* Affiliation: LIP6 - Faculté des Sciences - Sorbonne Université\n",
        "* Email: mohamed-amine.baazizi@lip6.fr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spark Setup (with Deequ enabled)"
      ],
      "metadata": {
        "id": "VlBYMn_k-OQ7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hohU-y8e_tdY"
      },
      "source": [
        "## vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjomDqxaDSPq"
      },
      "source": [
        "## DT data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9JoybcFDtIg"
      },
      "source": [
        "schema = 'age string, income string, student string, credit_rating string, label string'\n",
        "data = spark.sparkContext.parallelize(tuples).toDF(schema)\n",
        "data.printSchema()\n",
        "data.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clLZvql7dEXf"
      },
      "source": [
        "## Transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtg9yaErDM4A"
      },
      "source": [
        "### String indexer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtUd5I-GCnHF"
      },
      "source": [
        "field = 'age'\n",
        "age_indexer = StringIndexer(inputCol=field,outputCol='indexed_'+field)\n",
        "df_age_idx = age_indexer.fit(data).transform(data)\n",
        "df_age_idx.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91WoptYoV3oD"
      },
      "source": [
        "def string_index_cols(cols,prefix):\n",
        "  outCols = map(lambda c:prefix+c, cols)\n",
        "  # return list(outCols)\n",
        "  return StringIndexer(inputCols=cols,outputCols=list(outCols))\n",
        "  \n",
        "\n",
        "# si = index_cols(['age','income'])\n",
        "# si.getOutputCols()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7-FDmGhgzeB"
      },
      "source": [
        "prefix = 'indexed_'\n",
        "fields = ['age','income']\n",
        "age_income_indexer = string_index_cols(fields,prefix)\n",
        "df_age_income_idx = age_income_indexer.fit(data).transform(data)\n",
        "df_age_income_idx.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgqQ8E38YGdd"
      },
      "source": [
        "### IndexToString"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIWFiC4NU8LZ"
      },
      "source": [
        "age_rev_indexer = IndexToString(inputCol=age_indexer.getOutputCol(),outputCol='original_age')\n",
        "\n",
        "df_orig_age =age_rev_indexer.transform(df_age_idx)\n",
        "df_orig_age.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5E5tjqac9Vg"
      },
      "source": [
        "### one-hot encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTeSQevLdKHz"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qde-cCKbLAM"
      },
      "source": [
        "age_onehotenc = OneHotEncoder(inputCol=age_indexer.getOutputCol(),outputCol='cat_age')\n",
        "age_onehotenc.setDropLast(False)\n",
        "df_age_onehot = age_onehotenc.fit(df_age_idx).transform(df_age_idx)\n",
        "df_age_onehot.show()\n",
        "#   .setInputCols(Array(\"indexed_age\", \"indexed_income\"))\n",
        "#   .setOutputCols(Array(\"category_age\", \"category_income\"))\n",
        "#   .setDropLast(false)\n",
        "\n",
        "# val encoded = oneHotEncoder.fit(data).transform(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NOANmixmkVl"
      },
      "source": [
        "### vector assembler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yac8m9-qiH26"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn25eBlJmnNL"
      },
      "source": [
        "cols = ['indexed_age','indexed_income']\n",
        "vec_assembler = VectorAssembler(inputCols= cols, outputCol= 'ageIncomeVec')\n",
        "                   \n",
        "df_age_income_vec = vec_assembler.transform(df_age_income_idx)\n",
        "df_age_income_vec.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMtNbOVtpAQy"
      },
      "source": [
        "### Vector Indexer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfWIwP6XrLSN"
      },
      "source": [
        "from pyspark.ml.feature import VectorIndexer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNgrnoTNnKsB"
      },
      "source": [
        "vecIndexer = VectorIndexer(inputCol='ageIncomeVec',\\\n",
        "                           outputCol='indexed_ageIncomeVec',\\\n",
        "                           maxCategories=3)\n",
        "df_age_income_vec_idx = vecIndexer.fit(df_age_income_vec).\\\n",
        "    transform(df_age_income_vec)  \n",
        "\n",
        "df_age_income_vec_idx.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIlplaNGt90T"
      },
      "source": [
        "## Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmpF_U7w0311"
      },
      "source": [
        "#### string indexer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhCTtbdCr_Ig"
      },
      "source": [
        "label = 'label'\n",
        "features_col = data.columns\n",
        "features_col.remove(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoxhCjhxxshT"
      },
      "source": [
        "prefix = 'indexed_'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLLssChaz-I1"
      },
      "source": [
        "label_string_indexer = StringIndexer(inputCol=label, outputCol=prefix+label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qRwqs7DzA__"
      },
      "source": [
        "features_str_col = list(map(lambda c:prefix+c, features_col))\n",
        "features_string_indexer = StringIndexer(inputCols=features_col,outputCols=features_str_col)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUfcmajh054k"
      },
      "source": [
        "#### vector assembler and indexer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cdg-KL6J0OJQ"
      },
      "source": [
        "vec_assembler = VectorAssembler(inputCols= features_string_indexer.getOutputCols(), outputCol= 'vector')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIT9jyQw1iXi"
      },
      "source": [
        "vec_indexer = VectorIndexer(inputCol='vector',\\\n",
        "                            outputCol='features',\\\n",
        "                           maxCategories=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyr9-SBC0_pT"
      },
      "source": [
        "#### pipeline building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX1OSzVl198X"
      },
      "source": [
        "stages = [label_string_indexer,features_string_indexer,vec_assembler,vec_indexer]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pes-99Ap0_Wb"
      },
      "source": [
        "from pyspark.ml import Pipeline \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erHGu8Bp1yx2"
      },
      "source": [
        "pipeline = Pipeline(stages = stages)\n",
        "train_data = pipeline.fit(data).transform(data).select(\"features\",\"indexed_label\")\n",
        "train_data.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKjgQqxo-3wy"
      },
      "source": [
        "## DT inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4lTg1kL2Q5f"
      },
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassificationModel, DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhFagPx2-6Ub",
        "outputId": "49e43402-bce5-4283-e8a6-ea7a6a547a21"
      },
      "source": [
        "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol= \"indexed_label\")\n",
        "dtModel = dt.fit(train_data)\n",
        "dtModel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_c7ec3cc2c2ef, depth=4, numNodes=13, numClasses=2, numFeatures=4"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80sLZK5uAWop"
      },
      "source": [
        "print(dtModel.toDebugString)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wluWPgjzB3BE"
      },
      "source": [
        "## Model Selection and Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9lYeEW0B-Rr"
      },
      "source": [
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Nr4UzQ6CAQ2"
      },
      "source": [
        "\n",
        "dt_paramGrid = ParamGridBuilder()\\\n",
        "        .addGrid(dt.maxBins, [40,42])\\\n",
        "        .addGrid(dt.minInstancesPerNode, [10,100]) \\\n",
        "        .build()\n",
        "dt_paramGrid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DmryGJwIZiy"
      },
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "# Use BinaryClassificationEvaluator to evaluate our model\n",
        "evaluatorPR = BinaryClassificationEvaluator(labelCol = \"indexed_label\", rawPredictionCol = \"prediction\", metricName = \"areaUnderPR\")\n",
        "evaluatorAUC = BinaryClassificationEvaluator(labelCol = \"indexed_label\", rawPredictionCol = \"prediction\", metricName = \"areaUnderROC\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQPkECWLFGi-"
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psczK_-hCdWe"
      },
      "source": [
        "# Build out the cross validation\n",
        "\n",
        "#create k folds with k=5. \n",
        "cv = CrossValidator(estimator=dt, \\\n",
        "                    estimatorParamMaps=dt_paramGrid, \\\n",
        "                    evaluator=evaluatorPR, \\\n",
        "                    numFolds=5, \\\n",
        "                    parallelism=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfzYAaaGExZa"
      },
      "source": [
        "cvModel = cv.fit(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmxjG7vjG1Jy"
      },
      "source": [
        "bestModel = cvModel.bestModel\n",
        "print(bestModel.toDebugString)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i6NaJPAI7N7"
      },
      "source": [
        "train_pred = cvModel.transform(train_data)\n",
        "train_pred.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvDVyDFBJUlC"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}